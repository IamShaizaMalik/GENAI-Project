{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MAH6GBlYm"
      },
      "source": [
        "# Japanese Legal Textual Entailment Solution for COLIEE 2025\n",
        "\n",
        "This notebook implements a complete solution for the Legal Textual Entailment task from COLIEE 2025 using the **original Japanese dataset** with a multilingual model (XLM-RoBERTa).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifAfE8axBlYp"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUI1AQlxBlYq",
        "outputId": "ee601697-6e72-483e-9198-9f91ff598713"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import transformers\n",
        "import transformers\n",
        "print(f\"Using transformers version: {transformers.__version__}\")\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using transformers version: 4.48.3\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3GahbREBlYr"
      },
      "source": [
        "## 2. Upload and Extract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "5mB8QhvXBlYr",
        "outputId": "df4b2e58-8868-4c42-8c62-63a7b0e0b51d"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload the RAR file with Japanese dataset\n",
        "\n",
        "# Install unrar if needed\n",
        "!apt-get install -y unrar\n",
        "\n",
        "# Extract the dataset\n",
        "!mkdir -p coileestatute\n",
        "!unrar x coileestatute.rar"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ec9d94c7-2643-4eee-8bce-326ce593dc8e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ec9d94c7-2643-4eee-8bce-326ce593dc8e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving COLIEE2025statute_data-Japanese.zip to COLIEE2025statute_data-Japanese.zip\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "Cannot open coileestatute.rar\n",
            "No such file or directory\n",
            "No files to extract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UAK1KbWBlYr"
      },
      "source": [
        "## 3. Define Dataset Class for Japanese Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxFXvLwBBlYr"
      },
      "source": [
        "class JapaneseLegalEntailmentDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for Japanese legal entailment training.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, tokenizer, civil_code=None):\n",
        "        \"\"\"\n",
        "        Initialize the dataset.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing training data\n",
        "            tokenizer: Tokenizer for encoding inputs\n",
        "            civil_code: Dictionary of civil code articles\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.civil_code = civil_code\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        query = row['query']\n",
        "        article_text = row['article_text']\n",
        "        label = 1 if row['label'] == 'Y' else 0\n",
        "\n",
        "        # For Japanese text, we don't need to add spaces between tokens\n",
        "        # XLM-RoBERTa tokenizer will handle this correctly\n",
        "        encoding = self.tokenizer(\n",
        "            article_text,\n",
        "            query,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Remove batch dimension\n",
        "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "        encoding['labels'] = torch.tensor(label)\n",
        "\n",
        "        return encoding"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLzNiRvGBlYs"
      },
      "source": [
        "## 4. Define Main System Class for Japanese Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xc-7Jv9BlYs"
      },
      "source": [
        "class JapaneseLegalEntailmentSystem:\n",
        "    \"\"\"\n",
        "    Main class for the Japanese Legal Textual Entailment System.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_path, model_name=\"xlm-roberta-base\"):\n",
        "        \"\"\"\n",
        "        Initialize the Japanese Legal Entailment System.\n",
        "\n",
        "        Args:\n",
        "            base_path: Path to the dataset directory\n",
        "            model_name: Name of the pre-trained model to use\n",
        "        \"\"\"\n",
        "        self.base_path = base_path\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.retrieval_model = None\n",
        "        self.entailment_model = None\n",
        "        self.civil_code = {}\n",
        "        self.civil_code_embeddings = None\n",
        "        self.threshold = 0.5  # Default threshold, will be optimized during training\n",
        "\n",
        "    def load_civil_code(self, file_path):\n",
        "        \"\"\"\n",
        "        Load and parse the Japanese civil code articles.\n",
        "\n",
        "        Args:\n",
        "            file_path: Path to the civil code text file\n",
        "        \"\"\"\n",
        "        print(\"Loading Japanese civil code articles...\")\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Extract articles using regex\n",
        "        # Japanese pattern for \"Article X:\" (条文 X:)\n",
        "        article_pattern = r'第(\\d+(?:-\\d+)?)条:(.+?)(?=第\\d+条:|$)'\n",
        "        articles = re.findall(article_pattern, content, re.DOTALL)\n",
        "\n",
        "        # Process and store articles\n",
        "        for article_num, article_text in articles:\n",
        "            # Clean article text\n",
        "            article_text = re.sub(r'\\n\\d+:', ' ', article_text)  # Replace paragraph numbers\n",
        "            article_text = re.sub(r'\\s+', ' ', article_text).strip()  # Normalize whitespace\n",
        "            self.civil_code[article_num] = article_text\n",
        "\n",
        "        print(f\"Loaded {len(self.civil_code)} Japanese civil code articles.\")\n",
        "\n",
        "    def load_training_data(self, directory):\n",
        "        \"\"\"\n",
        "        Load and parse the Japanese training data from XML files.\n",
        "\n",
        "        Args:\n",
        "            directory: Directory containing training XML files\n",
        "\n",
        "        Returns:\n",
        "            DataFrame containing training data\n",
        "        \"\"\"\n",
        "        print(\"Loading Japanese training data...\")\n",
        "        data = []\n",
        "\n",
        "        # List all XML files in the directory\n",
        "        xml_files = [f for f in os.listdir(directory) if f.endswith('.xml')]\n",
        "\n",
        "        for xml_file in xml_files:\n",
        "            file_path = os.path.join(directory, xml_file)\n",
        "            tree = ET.parse(file_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            for pair in root.findall('pair'):\n",
        "                pair_id = pair.get('id')\n",
        "                label = pair.get('label')\n",
        "                t1 = pair.find('t1').text.strip() if pair.find('t1') is not None else \"\"\n",
        "                t2 = pair.find('t2').text.strip() if pair.find('t2') is not None else \"\"\n",
        "\n",
        "                # Extract article numbers from t1\n",
        "                article_nums = self._extract_article_numbers(t1)\n",
        "\n",
        "                # Add engineered features\n",
        "                features = self._compute_features(t1, t2)\n",
        "\n",
        "                data.append({\n",
        "                    'id': pair_id,\n",
        "                    'article_text': t1,\n",
        "                    'query': t2,\n",
        "                    'label': label,\n",
        "                    'article_nums': article_nums,\n",
        "                    **features  # Add all computed features\n",
        "                })\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        print(f\"Loaded {len(df)} Japanese training examples.\")\n",
        "        return df\n",
        "\n",
        "    def _compute_features(self, article_text, query):\n",
        "        \"\"\"\n",
        "        Compute engineered features between Japanese article and query.\n",
        "\n",
        "        Args:\n",
        "            article_text: Article text\n",
        "            query: Query text\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of features\n",
        "        \"\"\"\n",
        "        # For Japanese, we use character-level features since words aren't separated by spaces\n",
        "        article_chars = set(article_text)\n",
        "        query_chars = set(query)\n",
        "\n",
        "        # Compute character overlap\n",
        "        if len(query_chars) > 0:\n",
        "            char_overlap_ratio = len(article_chars.intersection(query_chars)) / len(query_chars)\n",
        "        else:\n",
        "            char_overlap_ratio = 0\n",
        "\n",
        "        # Compute length features\n",
        "        article_length = len(article_text)\n",
        "        query_length = len(query)\n",
        "        length_ratio = query_length / article_length if article_length > 0 else 0\n",
        "\n",
        "        # Count specific Japanese legal terms (could be expanded)\n",
        "        legal_terms = ['法律', '条文', '権利', '義務', '契約']\n",
        "        term_counts = {}\n",
        "\n",
        "        for term in legal_terms:\n",
        "            term_counts[f'article_{term}_count'] = article_text.count(term)\n",
        "            term_counts[f'query_{term}_count'] = query.count(term)\n",
        "\n",
        "        return {\n",
        "            'char_overlap_ratio': char_overlap_ratio,\n",
        "            'article_length': article_length,\n",
        "            'query_length': query_length,\n",
        "            'length_ratio': length_ratio,\n",
        "            **term_counts\n",
        "        }\n",
        "\n",
        "    def _extract_article_numbers(self, text):\n",
        "        \"\"\"\n",
        "        Extract article numbers from Japanese text.\n",
        "\n",
        "        Args:\n",
        "            text: Text containing article references\n",
        "\n",
        "        Returns:\n",
        "            List of article numbers\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return []\n",
        "\n",
        "        # Pattern to match \"Article X:\" in Japanese (第X条)\n",
        "        pattern = r'第(\\d+(?:-\\d+)?)条'\n",
        "        matches = re.findall(pattern, text)\n",
        "        return matches\n",
        "\n",
        "    def create_embeddings(self, texts, batch_size=8):\n",
        "        \"\"\"\n",
        "        Create embeddings for a list of Japanese texts.\n",
        "\n",
        "        Args:\n",
        "            texts: List of texts to embed\n",
        "            batch_size: Batch size for processing\n",
        "\n",
        "        Returns:\n",
        "            Numpy array of embeddings\n",
        "        \"\"\"\n",
        "        model = AutoModel.from_pretrained(self.model_name).to(device)\n",
        "        embeddings = []\n",
        "\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            inputs = self.tokenizer(batch_texts, padding=True, truncation=True,\n",
        "                                   max_length=512, return_tensors=\"pt\").to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            # Use CLS token embedding as the sentence embedding\n",
        "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(batch_embeddings)\n",
        "\n",
        "        return np.vstack(embeddings)\n",
        "\n",
        "    def build_retrieval_index(self):\n",
        "        \"\"\"\n",
        "        Build the retrieval index for Japanese civil code articles.\n",
        "        \"\"\"\n",
        "        print(\"Building retrieval index for Japanese articles...\")\n",
        "        # Prepare texts for embedding\n",
        "        article_nums = list(self.civil_code.keys())\n",
        "        article_texts = [self.civil_code[num] for num in article_nums]\n",
        "\n",
        "        # Create embeddings\n",
        "        self.civil_code_embeddings = self.create_embeddings(article_texts)\n",
        "        self.article_nums = article_nums\n",
        "\n",
        "        print(f\"Created embeddings for {len(article_nums)} Japanese articles.\")\n",
        "\n",
        "    def retrieve_articles(self, query, top_k=5):\n",
        "        \"\"\"\n",
        "        Retrieve relevant Japanese articles for a query.\n",
        "\n",
        "        Args:\n",
        "            query: Query text\n",
        "            top_k: Number of articles to retrieve\n",
        "\n",
        "        Returns:\n",
        "            List of (article_num, score) tuples\n",
        "        \"\"\"\n",
        "        # Create query embedding\n",
        "        query_embedding = self.create_embeddings([query])\n",
        "\n",
        "        # Calculate similarity scores\n",
        "        similarity_scores = cosine_similarity(query_embedding, self.civil_code_embeddings)[0]\n",
        "\n",
        "        # Get top-k articles\n",
        "        top_indices = np.argsort(-similarity_scores)[:top_k]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            article_num = self.article_nums[idx]\n",
        "            score = similarity_scores[idx]\n",
        "            results.append((article_num, score))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def train_entailment_model(self, train_df, val_df=None, epochs=5, batch_size=8):\n",
        "        \"\"\"\n",
        "        Train the entailment model for Japanese text using PyTorch directly with engineered features\n",
        "        and layer freezing.\n",
        "\n",
        "        Args:\n",
        "            train_df: Training data DataFrame\n",
        "            val_df: Validation data DataFrame\n",
        "            epochs: Number of training epochs\n",
        "            batch_size: Training batch size\n",
        "        \"\"\"\n",
        "        print(\"Training Japanese entailment model...\")\n",
        "\n",
        "        # Calculate class weights to handle imbalance\n",
        "        y_train = [1 if label == 'Y' else 0 for label in train_df['label']]\n",
        "        class_counts = np.bincount(y_train)\n",
        "        print(f\"Class distribution in training data: {class_counts[0]} negative, {class_counts[1]} positive\")\n",
        "\n",
        "        # Prepare datasets\n",
        "        train_dataset = JapaneseLegalEntailmentDataset(train_df, self.tokenizer, self.civil_code)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        if val_df is not None:\n",
        "            val_dataset = JapaneseLegalEntailmentDataset(val_df, self.tokenizer, self.civil_code)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "        # Initialize model\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            self.model_name,\n",
        "            num_labels=2\n",
        "        ).to(device)\n",
        "\n",
        "        # Freeze the first 8 layers of the model\n",
        "        print(\"Freezing first 8 layers of the model...\")\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'roberta.encoder.layer' in name:\n",
        "                layer_num = int(name.split('.')[3])\n",
        "                if layer_num < 8:  # Freeze first 8 layers (0-7)\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        # Count trainable parameters\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.1%} of total)\")\n",
        "\n",
        "        # Set up optimizer with lower learning rate for Japanese\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "        # Use weighted loss function if classes are imbalanced\n",
        "        if abs(class_counts[0] - class_counts[1]) > 50:  # Arbitrary threshold for imbalance\n",
        "            weight = torch.tensor([1.0, class_counts[0]/class_counts[1]]).to(device)\n",
        "            loss_fn = torch.nn.CrossEntropyLoss(weight=weight)\n",
        "            print(f\"Using weighted loss with weights: {weight.cpu().numpy()}\")\n",
        "        else:\n",
        "            loss_fn = torch.nn.CrossEntropyLoss()\n",
        "            print(\"Using standard loss (classes are balanced)\")\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch in train_loader:\n",
        "                # Move batch to device\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "                labels = batch.pop('labels')\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(**batch)\n",
        "                logits = outputs.logits\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = loss_fn(logits, labels)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # Validation\n",
        "            if val_df is not None:\n",
        "                model.eval()\n",
        "                val_preds = []\n",
        "                val_labels = []\n",
        "                val_probs = []\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for batch in val_loader:\n",
        "                        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "                        labels = batch.pop('labels')\n",
        "\n",
        "                        outputs = model(**batch)\n",
        "                        logits = outputs.logits\n",
        "                        probs = torch.softmax(logits, dim=1)[:, 1]  # Probability of positive class\n",
        "                        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "                        val_preds.extend(preds.cpu().numpy())\n",
        "                        val_labels.extend(labels.cpu().numpy())\n",
        "                        val_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "                # Calculate metrics with default threshold (0.5)\n",
        "                accuracy = accuracy_score(val_labels, val_preds)\n",
        "                f1 = f1_score(val_labels, val_preds)\n",
        "                precision = precision_score(val_labels, val_preds)\n",
        "                recall = recall_score(val_labels, val_preds)\n",
        "\n",
        "                print(f\"Validation Metrics (threshold=0.5):\")\n",
        "                print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "                print(f\"  F1 Score: {f1:.4f}\")\n",
        "                print(f\"  Precision: {precision:.4f}\")\n",
        "                print(f\"  Recall: {recall:.4f}\")\n",
        "\n",
        "                # Find best threshold\n",
        "                best_f1 = 0\n",
        "                best_threshold = 0.5\n",
        "                thresholds = np.arange(0.3, 0.8, 0.05)\n",
        "\n",
        "                for threshold in thresholds:\n",
        "                    threshold_preds = [1 if p > threshold else 0 for p in val_probs]\n",
        "                    threshold_f1 = f1_score(val_labels, threshold_preds)\n",
        "                    if threshold_f1 > best_f1:\n",
        "                        best_f1 = threshold_f1\n",
        "                        best_threshold = threshold\n",
        "\n",
        "                # Calculate metrics with best threshold\n",
        "                best_preds = [1 if p > best_threshold else 0 for p in val_probs]\n",
        "                best_accuracy = accuracy_score(val_labels, best_preds)\n",
        "                best_precision = precision_score(val_labels, best_preds)\n",
        "                best_recall = recall_score(val_labels, best_preds)\n",
        "\n",
        "                print(f\"Best threshold: {best_threshold:.2f}\")\n",
        "                print(f\"Validation Metrics (threshold={best_threshold:.2f}):\")\n",
        "                print(f\"  Accuracy: {best_accuracy:.4f}\")\n",
        "                print(f\"  F1 Score: {best_f1:.4f}\")\n",
        "                print(f\"  Precision: {best_precision:.4f}\")\n",
        "                print(f\"  Recall: {best_recall:.4f}\")\n",
        "\n",
        "                # Save best threshold for prediction\n",
        "                self.threshold = best_threshold\n",
        "\n",
        "        self.entailment_model = model\n",
        "        print(\"Japanese entailment model training completed.\")\n",
        "\n",
        "    def predict_entailment(self, query, retrieved_articles):\n",
        "        \"\"\"\n",
        "        Predict entailment for a Japanese query and retrieved articles.\n",
        "\n",
        "        Args:\n",
        "            query: Query text\n",
        "            retrieved_articles: List of (article_num, score) tuples\n",
        "\n",
        "        Returns:\n",
        "            Entailment prediction (True/False)\n",
        "        \"\"\"\n",
        "        if not retrieved_articles:\n",
        "            return False\n",
        "\n",
        "        # Prepare inputs\n",
        "        inputs = []\n",
        "        for article_num, _ in retrieved_articles:\n",
        "            if article_num in self.civil_code:\n",
        "                article_text = self.civil_code[article_num]\n",
        "                inputs.append((article_text, query))\n",
        "\n",
        "        if not inputs:\n",
        "            return False\n",
        "\n",
        "        # Tokenize inputs\n",
        "        encoded_inputs = []\n",
        "        for article_text, query_text in inputs:\n",
        "            encoded = self.tokenizer(\n",
        "                article_text,\n",
        "                query_text,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=512,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            encoded_inputs.append(encoded)\n",
        "\n",
        "        # Make predictions\n",
        "        entailment_scores = []\n",
        "        for encoded in encoded_inputs:\n",
        "            encoded = {k: v.to(device) for k, v in encoded.items()}\n",
        "            with torch.no_grad():\n",
        "                outputs = self.entailment_model(**encoded)\n",
        "                logits = outputs.logits\n",
        "                probabilities = torch.softmax(logits, dim=1)\n",
        "                entailment_score = probabilities[0, 1].item()  # Probability of entailment (class 1)\n",
        "                entailment_scores.append(entailment_score)\n",
        "\n",
        "        # Aggregate scores (using max as a simple strategy)\n",
        "        max_score = max(entailment_scores)\n",
        "\n",
        "        # Use optimized threshold\n",
        "        return max_score > self.threshold\n",
        "\n",
        "    def process_test_data(self, test_file, output_task3, output_task4, system_id=\"SYSTEM\"):\n",
        "        \"\"\"\n",
        "        Process Japanese test data and generate output files for Task 3 and Task 4.\n",
        "\n",
        "        Args:\n",
        "            test_file: Path to test XML file\n",
        "            output_task3: Path to Task 3 output file\n",
        "            output_task4: Path to Task 4 output file\n",
        "            system_id: System identifier for output files\n",
        "        \"\"\"\n",
        "        print(f\"Processing Japanese test data from {test_file}...\")\n",
        "\n",
        "        # Parse test file\n",
        "        tree = ET.parse(test_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        task3_results = []\n",
        "        task4_results = []\n",
        "\n",
        "        for pair in root.findall('pair'):\n",
        "            pair_id = pair.get('id')\n",
        "            query = pair.find('t2').text.strip() if pair.find('t2') is not None else \"\"\n",
        "\n",
        "            # Task 3: Retrieve relevant articles\n",
        "            retrieved_articles = self.retrieve_articles(query, top_k=5)\n",
        "\n",
        "            # Write Task 3 results\n",
        "            for rank, (article_num, score) in enumerate(retrieved_articles, 1):\n",
        "                task3_line = f\"{pair_id} Q0 {article_num} {rank} {score:.6f} {system_id}\"\n",
        "                task3_results.append(task3_line)\n",
        "\n",
        "            # Task 4: Predict entailment\n",
        "            is_entailed = self.predict_entailment(query, retrieved_articles)\n",
        "            task4_line = f\"{pair_id} {'Y' if is_entailed else 'N'} {system_id}\"\n",
        "            task4_results.append(task4_line)\n",
        "\n",
        "        # Write output files\n",
        "        with open(output_task3, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(task3_results))\n",
        "\n",
        "        with open(output_task4, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(task4_results))\n",
        "\n",
        "        print(f\"Task 3 results written to {output_task3}\")\n",
        "        print(f\"Task 4 results written to {output_task4}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCEzWcb7BlYt"
      },
      "source": [
        "## 5. Run the System on Japanese Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laLXX_a0BlYt"
      },
      "source": [
        "# Set paths for Japanese dataset\n",
        "base_path = \"/content/coileestatute/COLIEE2025statute_data\"\n",
        "civil_code_path = os.path.join(base_path, \"text/civil_code_jp-1to724.txt\")\n",
        "train_dir = os.path.join(base_path, \"train\")\n",
        "\n",
        "# Initialize system with XLM-RoBERTa (multilingual model)\n",
        "system = JapaneseLegalEntailmentSystem(base_path, model_name=\"xlm-roberta-base\")\n",
        "\n",
        "# Load Japanese civil code\n",
        "system.load_civil_code(civil_code_path)\n",
        "\n",
        "# Load Japanese training data\n",
        "train_df = system.load_training_data(train_dir)\n",
        "\n",
        "# Split data for training and validation\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build retrieval index\n",
        "system.build_retrieval_index()\n",
        "\n",
        "# Train entailment model\n",
        "system.train_entailment_model(train_df, val_df, epochs=5)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unMGLUSuBlYu"
      },
      "source": [
        "## 6. Process Test Data and Generate Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu-2fwhBBlYu"
      },
      "source": [
        "# For demonstration, we'll use one of the training files as a mock test file\n",
        "test_file = os.path.join(train_dir, \"riteval_R05.xml\")\n",
        "output_task3 = \"task3.YOURID\"\n",
        "output_task4 = \"task4.YOURID\"\n",
        "system.process_test_data(test_file, output_task3, output_task4, system_id=\"YOURID\")\n",
        "\n",
        "# Download the result files\n",
        "from google.colab import files\n",
        "files.download(output_task3)\n",
        "files.download(output_task4)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmbLBb6aBlYu"
      },
      "source": [
        "## 7. Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4FymbBnBlYu"
      },
      "source": [
        "# Let's evaluate on the validation set\n",
        "val_results = []\n",
        "for _, row in val_df.iterrows():\n",
        "    query = row['query']\n",
        "    true_label = 1 if row['label'] == 'Y' else 0\n",
        "\n",
        "    # Retrieve articles\n",
        "    retrieved_articles = system.retrieve_articles(query, top_k=5)\n",
        "\n",
        "    # Predict entailment\n",
        "    is_entailed = system.predict_entailment(query, retrieved_articles)\n",
        "    pred_label = 1 if is_entailed else 0\n",
        "\n",
        "    val_results.append((true_label, pred_label))\n",
        "\n",
        "# Calculate metrics\n",
        "true_labels, pred_labels = zip(*val_results)\n",
        "accuracy = accuracy_score(true_labels, pred_labels)\n",
        "f1 = f1_score(true_labels, pred_labels)\n",
        "precision = precision_score(true_labels, pred_labels)\n",
        "recall = recall_score(true_labels, pred_labels)\n",
        "\n",
        "print(f\"Validation Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWdBRy0HBlYu"
      },
      "source": [
        "## 8. Comparison with English Model (Optional)\n",
        "\n",
        "If you have results from both the English and Japanese models, you can compare them here to see which performs better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSga0XdTBlYu"
      },
      "source": [
        "# Example comparison code (replace with your actual results)\n",
        "english_metrics = {\n",
        "    'accuracy': 0.4875,\n",
        "    'f1': 0.6555,\n",
        "    'precision': 0.4875,\n",
        "    'recall': 1.0000\n",
        "}\n",
        "\n",
        "japanese_metrics = {\n",
        "    'accuracy': accuracy,\n",
        "    'f1': f1,\n",
        "    'precision': precision,\n",
        "    'recall': recall\n",
        "}\n",
        "\n",
        "# Create comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'F1 Score', 'Precision', 'Recall'],\n",
        "    'English Model': [english_metrics['accuracy'], english_metrics['f1'],\n",
        "                     english_metrics['precision'], english_metrics['recall']],\n",
        "    'Japanese Model': [japanese_metrics['accuracy'], japanese_metrics['f1'],\n",
        "                      japanese_metrics['precision'], japanese_metrics['recall']],\n",
        "    'Difference': [japanese_metrics['accuracy'] - english_metrics['accuracy'],\n",
        "                  japanese_metrics['f1'] - english_metrics['f1'],\n",
        "                  japanese_metrics['precision'] - english_metrics['precision'],\n",
        "                  japanese_metrics['recall'] - english_metrics['recall']]\n",
        "})\n",
        "\n",
        "comparison_df"
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}